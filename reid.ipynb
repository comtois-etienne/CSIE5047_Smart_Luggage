{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "class vehicle movement predictor\n",
    "put vehicle to x0,y0,a0 and rotate all the points\n",
    "receive vehicle north and host point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vision import Camera\n",
    "\n",
    "mba_video_camera = Camera(\n",
    "    h_fov=59.0,\n",
    "    h_res=1080,\n",
    "    v_res=720,\n",
    ")\n",
    "\n",
    "mba_photo_camera = Camera(\n",
    "    h_fov=67.0,\n",
    "    h_res=1290,\n",
    "    v_res=720,\n",
    ")\n",
    "\n",
    "zed_two_camera = Camera(\n",
    "    h_fov=110.0,\n",
    "    v_fov=70.0,\n",
    ")\n",
    "\n",
    "avg_shoulder_width = 350.0\n",
    "avg_torso_height = 460.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Point(x=0, y=0, a=None), Point(x=1200, y=0, a=None), Point(x=2200, y=0, a=None), Point(x=4200, y=0, a=None), Point(x=3000, y=1280, a=None), Point(x=3995, y=1590, a=None), Point(x=3005, y=-1150, a=None), Point(x=4000, y=-1490, a=None)]\n"
     ]
    }
   ],
   "source": [
    "from src.point import Point\n",
    "\n",
    "ref_points = [\n",
    "    Point(0, 0),\n",
    "    Point(1200, 0),\n",
    "    Point(2200, 0),\n",
    "    Point(4200, 0),\n",
    "    Point(3000, 1280),\n",
    "    Point(3995, 1590),\n",
    "    Point(3005, -1150),\n",
    "    Point(4000, -1490),\n",
    "]\n",
    "print(ref_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv8 For human and objects detection\n",
    "\n",
    "First attempt at human positioning with YOLOv8. Unsure if will be usefull because of the RGBD camera. It lets us estimates the angle between the camera and the person. Could also be usefull for object detection and avoidance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 8.06\n"
     ]
    }
   ],
   "source": [
    "from src.vision import PositionEstimator, VideoCapture\n",
    "import mediapipe as mp\n",
    "from src.vision import VideoCapture\n",
    "from src.vision import ObjectDetector\n",
    "from src.vision import plot_obj\n",
    "from ultralytics import YOLO\n",
    "from src.vision import ReID\n",
    "import time\n",
    "\n",
    "verbose = False\n",
    "refresh_rate = 1\n",
    "camera = mba_video_camera\n",
    "yolo_model = YOLO('yolov8s.pt')\n",
    "obj_detector = ObjectDetector(yolo_model, camera)\n",
    "pe = PositionEstimator(\n",
    "    mp.solutions.pose, \n",
    "    camera,\n",
    "    avg_torso_height, \n",
    "    file_path='pe.csv',\n",
    "    queue_size=3,\n",
    "    kernel_size=3\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Initiate the camera\n",
    "    # cap = VideoCapture('./Movie on 2023-11-23 at 10.03.mov')\n",
    "    # cap = VideoCapture('./Movie on 2023-12-11 at 21.01.mov')\n",
    "    # cap = VideoCapture('./Movie on 2023-12-11 at 21.02.mov')\n",
    "    cap = VideoCapture(0)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # cap.skip_frames(14)\n",
    "    frame = cap.grab_frame()\n",
    "    obj_detector.detect(frame)\n",
    "    host = obj_detector.get_objs_by_name('person', score=0.4).iloc[0]\n",
    "    reid = ReID(frame, host, 32, 0.80)\n",
    "\n",
    "    while True:\n",
    "        start = time.time()\n",
    "        # cap.skip_frames(5)\n",
    "        frame = cap.grab_frame()\n",
    "        if frame is None: break\n",
    "        \n",
    "        obj_detector.detect(frame)\n",
    "        objs = obj_detector.get_objs_by_name('person', score=0.4)\n",
    "        host, objs = reid.reid(frame, objs)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        fig, ax = plt.subplots() if verbose else (None, None)\n",
    "\n",
    "        if host is not None:\n",
    "            bo_frame = PositionEstimator.mask_frame(frame, host)\n",
    "            result = pe.save_position(bo_frame, 1.15, verbose=verbose)\n",
    "            if result is not None and verbose:\n",
    "                print('result')\n",
    "                pe.plot_result(ax, frame, result, camera)\n",
    "        else:\n",
    "            pe.save_blank()\n",
    "\n",
    "        ax.imshow(frame) if verbose else None\n",
    "        # ax.imshow(bo_frame) if verbose else None\n",
    "\n",
    "        if verbose:\n",
    "            plot_obj(ax, host, 'r') if host is not None else None\n",
    "            for index, obj in objs.iterrows():\n",
    "                plot_obj(ax, obj, 'y')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        delta = time.time() - start\n",
    "        # print(f'FPS: {1/delta:.2f}')\n",
    "        pause = (1 / refresh_rate) - delta\n",
    "        if pause > 0: time.sleep(pause)\n",
    "        delta = time.time() - start\n",
    "        # print(f'FPS: {1/delta:.2f}')\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    cap.release()  # Release the camera resource\n",
    "\n",
    "cap.release()  # Release the camera resource if break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
