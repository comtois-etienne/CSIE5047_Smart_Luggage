{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sensor import Camera\n",
    "\n",
    "mba_video_camera = Camera(\n",
    "    h_fov=59.0,\n",
    "    h_res=1080,\n",
    "    v_res=720,\n",
    ")\n",
    "\n",
    "mba_photo_camera = Camera(\n",
    "    h_fov=67.0,\n",
    "    h_res=1290,\n",
    "    v_res=720,\n",
    ")\n",
    "\n",
    "zed_two_camera = Camera(\n",
    "    h_fov=110.0,\n",
    "    v_fov=70.0,\n",
    ")\n",
    "\n",
    "avg_shoulder_width = 350.0\n",
    "avg_torso_height = 460.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv8 For human and objects detection\n",
    "\n",
    "First attempt at human positioning with YOLOv8. Unsure if will be usefull because of the RGBD camera. It lets us estimates the angle between the camera and the person. Could also be usefull for object detection and avoidance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1702584722.614772       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M1\n",
      "[ WARN:0@216.921] global /private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_11nitadzeg/croot/opencv-suite_1691620374638/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "from src.point import Point\n",
    "from src.vision import PositionEstimator, VideoCapture\n",
    "import mediapipe as mp\n",
    "from src.vision import VideoCapture\n",
    "from src.vision import ObjectDetector\n",
    "from src.vision import plot_obj\n",
    "from ultralytics import YOLO\n",
    "from src.vision import ReID\n",
    "import time\n",
    "\n",
    "\n",
    "verbose = False\n",
    "refresh_rate = 1\n",
    "camera = mba_video_camera\n",
    "yolo_model = YOLO('yolov8s.pt')\n",
    "obj_detector = ObjectDetector(yolo_model, camera)\n",
    "pe = PositionEstimator(\n",
    "    mp.solutions.pose, \n",
    "    camera,\n",
    "    avg_torso_height, \n",
    "    file_path='pe.csv',\n",
    "    queue_size=3,\n",
    "    kernel_size=3\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    # Initiate the camera\n",
    "    # cap = VideoCapture('./Movie on 2023-11-23 at 10.03.mov')\n",
    "    # cap = VideoCapture('./Movie on 2023-12-11 at 21.01.mov')\n",
    "    # cap = VideoCapture('./Movie on 2023-12-11 at 21.02.mov')\n",
    "    cap = VideoCapture(0)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # cap.skip_frames(14)\n",
    "    frame = cap.grab_frame()\n",
    "    obj_detector.detect(frame)\n",
    "    host = obj_detector.get_objs_by_name('person', score=0.4).iloc[0]\n",
    "    reid = ReID(frame, host, 32, 0.80)\n",
    "\n",
    "    while True:\n",
    "        start = time.time()\n",
    "        # cap.skip_frames(5)\n",
    "        frame = cap.grab_frame()\n",
    "        if frame is None: break\n",
    "        \n",
    "        obj_detector.detect(frame)\n",
    "        objs = obj_detector.get_objs_by_name('person', score=0.4)\n",
    "        host, objs = reid.reid(frame, objs)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        fig, ax = plt.subplots() if verbose else (None, None)\n",
    "\n",
    "        if host is not None:\n",
    "            bo_frame = PositionEstimator.mask_frame(frame, host)\n",
    "            result = pe.save_position(bo_frame, 1.15, verbose=verbose)\n",
    "            if result is not None and verbose:\n",
    "                print('result')\n",
    "                pe.plot_result(ax, frame, result, camera)\n",
    "        else:\n",
    "            pe.save_blank()\n",
    "\n",
    "        ax.imshow(frame) if verbose else None\n",
    "        # ax.imshow(bo_frame) if verbose else None\n",
    "\n",
    "        if verbose:\n",
    "            plot_obj(ax, host, 'r') if host is not None else None\n",
    "            for index, obj in objs.iterrows():\n",
    "                plot_obj(ax, obj, 'y')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        delta = time.time() - start\n",
    "        # print(f'FPS: {1/delta:.2f}')\n",
    "        pause = (1 / refresh_rate) - delta\n",
    "        if pause > 0: time.sleep(pause)\n",
    "        delta = time.time() - start\n",
    "        # print(f'FPS: {1/delta:.2f}')\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    cap.release()  # Release the camera resource\n",
    "\n",
    "cap.release()  # Release the camera resource if break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
